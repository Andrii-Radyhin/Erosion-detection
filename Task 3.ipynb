{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "853683b0-8e35-4367-bc88-52d5a7eee191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d60e87cd-91b6-4f3c-a7a0-d029a9d2812c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236</td>\n",
       "      <td>488</td>\n",
       "      <td>16</td>\n",
       "      <td>221</td>\n",
       "      <td>382</td>\n",
       "      <td>97</td>\n",
       "      <td>-4.472136</td>\n",
       "      <td>0.107472</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>13.340874</td>\n",
       "      <td>0.870542</td>\n",
       "      <td>1.962937</td>\n",
       "      <td>7.466666</td>\n",
       "      <td>11.547794</td>\n",
       "      <td>8.822916</td>\n",
       "      <td>9.046424</td>\n",
       "      <td>7.895535</td>\n",
       "      <td>11.010677</td>\n",
       "      <td>20.107472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>386</td>\n",
       "      <td>206</td>\n",
       "      <td>357</td>\n",
       "      <td>232</td>\n",
       "      <td>1</td>\n",
       "      <td>198</td>\n",
       "      <td>7.810250</td>\n",
       "      <td>0.763713</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>...</td>\n",
       "      <td>12.484882</td>\n",
       "      <td>7.168680</td>\n",
       "      <td>2.885415</td>\n",
       "      <td>12.413973</td>\n",
       "      <td>10.260494</td>\n",
       "      <td>10.091351</td>\n",
       "      <td>9.270888</td>\n",
       "      <td>3.173994</td>\n",
       "      <td>13.921871</td>\n",
       "      <td>61.763713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>429</td>\n",
       "      <td>49</td>\n",
       "      <td>481</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>146</td>\n",
       "      <td>8.602325</td>\n",
       "      <td>0.651162</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>...</td>\n",
       "      <td>14.030257</td>\n",
       "      <td>0.394970</td>\n",
       "      <td>8.160625</td>\n",
       "      <td>12.592059</td>\n",
       "      <td>8.937577</td>\n",
       "      <td>2.265191</td>\n",
       "      <td>11.255721</td>\n",
       "      <td>12.794841</td>\n",
       "      <td>12.080951</td>\n",
       "      <td>74.651162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>414</td>\n",
       "      <td>350</td>\n",
       "      <td>481</td>\n",
       "      <td>370</td>\n",
       "      <td>208</td>\n",
       "      <td>158</td>\n",
       "      <td>8.306624</td>\n",
       "      <td>0.424645</td>\n",
       "      <td>1</td>\n",
       "      <td>340</td>\n",
       "      <td>...</td>\n",
       "      <td>2.789577</td>\n",
       "      <td>6.416708</td>\n",
       "      <td>10.549814</td>\n",
       "      <td>11.456437</td>\n",
       "      <td>6.468099</td>\n",
       "      <td>2.519049</td>\n",
       "      <td>0.258284</td>\n",
       "      <td>9.317696</td>\n",
       "      <td>5.383098</td>\n",
       "      <td>69.424645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>318</td>\n",
       "      <td>359</td>\n",
       "      <td>20</td>\n",
       "      <td>218</td>\n",
       "      <td>317</td>\n",
       "      <td>301</td>\n",
       "      <td>8.124038</td>\n",
       "      <td>0.767304</td>\n",
       "      <td>1</td>\n",
       "      <td>212</td>\n",
       "      <td>...</td>\n",
       "      <td>1.886560</td>\n",
       "      <td>1.919999</td>\n",
       "      <td>2.268203</td>\n",
       "      <td>0.149421</td>\n",
       "      <td>4.105907</td>\n",
       "      <td>10.416291</td>\n",
       "      <td>6.816217</td>\n",
       "      <td>8.586960</td>\n",
       "      <td>4.512419</td>\n",
       "      <td>66.767304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89995</th>\n",
       "      <td>328</td>\n",
       "      <td>44</td>\n",
       "      <td>320</td>\n",
       "      <td>364</td>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "      <td>4.898979</td>\n",
       "      <td>0.563878</td>\n",
       "      <td>1</td>\n",
       "      <td>315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266362</td>\n",
       "      <td>6.185887</td>\n",
       "      <td>7.716837</td>\n",
       "      <td>10.144664</td>\n",
       "      <td>1.711649</td>\n",
       "      <td>3.849704</td>\n",
       "      <td>12.401903</td>\n",
       "      <td>14.195540</td>\n",
       "      <td>2.371207</td>\n",
       "      <td>24.563878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89996</th>\n",
       "      <td>217</td>\n",
       "      <td>472</td>\n",
       "      <td>174</td>\n",
       "      <td>327</td>\n",
       "      <td>255</td>\n",
       "      <td>389</td>\n",
       "      <td>-3.605551</td>\n",
       "      <td>0.861690</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>...</td>\n",
       "      <td>5.147059</td>\n",
       "      <td>4.209660</td>\n",
       "      <td>14.482770</td>\n",
       "      <td>1.375031</td>\n",
       "      <td>6.386263</td>\n",
       "      <td>10.107582</td>\n",
       "      <td>12.637902</td>\n",
       "      <td>6.576331</td>\n",
       "      <td>6.863238</td>\n",
       "      <td>13.861690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89997</th>\n",
       "      <td>189</td>\n",
       "      <td>406</td>\n",
       "      <td>213</td>\n",
       "      <td>57</td>\n",
       "      <td>494</td>\n",
       "      <td>190</td>\n",
       "      <td>6.164414</td>\n",
       "      <td>0.633704</td>\n",
       "      <td>1</td>\n",
       "      <td>221</td>\n",
       "      <td>...</td>\n",
       "      <td>14.902807</td>\n",
       "      <td>2.886534</td>\n",
       "      <td>8.683168</td>\n",
       "      <td>4.522339</td>\n",
       "      <td>1.556421</td>\n",
       "      <td>10.971184</td>\n",
       "      <td>7.792226</td>\n",
       "      <td>8.422623</td>\n",
       "      <td>3.041409</td>\n",
       "      <td>38.633704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89998</th>\n",
       "      <td>418</td>\n",
       "      <td>478</td>\n",
       "      <td>163</td>\n",
       "      <td>35</td>\n",
       "      <td>390</td>\n",
       "      <td>77</td>\n",
       "      <td>-3.605551</td>\n",
       "      <td>0.687309</td>\n",
       "      <td>0</td>\n",
       "      <td>289</td>\n",
       "      <td>...</td>\n",
       "      <td>12.743029</td>\n",
       "      <td>2.525611</td>\n",
       "      <td>11.050145</td>\n",
       "      <td>6.589943</td>\n",
       "      <td>12.622192</td>\n",
       "      <td>10.596839</td>\n",
       "      <td>0.647584</td>\n",
       "      <td>8.746364</td>\n",
       "      <td>1.246682</td>\n",
       "      <td>13.687309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89999</th>\n",
       "      <td>244</td>\n",
       "      <td>335</td>\n",
       "      <td>337</td>\n",
       "      <td>152</td>\n",
       "      <td>386</td>\n",
       "      <td>202</td>\n",
       "      <td>7.681146</td>\n",
       "      <td>0.613207</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>11.069077</td>\n",
       "      <td>6.303448</td>\n",
       "      <td>14.031393</td>\n",
       "      <td>1.877340</td>\n",
       "      <td>13.361607</td>\n",
       "      <td>2.164695</td>\n",
       "      <td>11.255181</td>\n",
       "      <td>3.404303</td>\n",
       "      <td>9.587379</td>\n",
       "      <td>59.613207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90000 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5         6         7  8    9  ...  \\\n",
       "0      236  488   16  221  382   97 -4.472136  0.107472  0  132  ...   \n",
       "1      386  206  357  232    1  198  7.810250  0.763713  1  143  ...   \n",
       "2      429   49  481  111  111  146  8.602325  0.651162  1  430  ...   \n",
       "3      414  350  481  370  208  158  8.306624  0.424645  1  340  ...   \n",
       "4      318  359   20  218  317  301  8.124038  0.767304  1  212  ...   \n",
       "...    ...  ...  ...  ...  ...  ...       ...       ... ..  ...  ...   \n",
       "89995  328   44  320  364    7   73  4.898979  0.563878  1  315  ...   \n",
       "89996  217  472  174  327  255  389 -3.605551  0.861690  0  144  ...   \n",
       "89997  189  406  213   57  494  190  6.164414  0.633704  1  221  ...   \n",
       "89998  418  478  163   35  390   77 -3.605551  0.687309  0  289  ...   \n",
       "89999  244  335  337  152  386  202  7.681146  0.613207  1   26  ...   \n",
       "\n",
       "              44        45         46         47         48         49  \\\n",
       "0      13.340874  0.870542   1.962937   7.466666  11.547794   8.822916   \n",
       "1      12.484882  7.168680   2.885415  12.413973  10.260494  10.091351   \n",
       "2      14.030257  0.394970   8.160625  12.592059   8.937577   2.265191   \n",
       "3       2.789577  6.416708  10.549814  11.456437   6.468099   2.519049   \n",
       "4       1.886560  1.919999   2.268203   0.149421   4.105907  10.416291   \n",
       "...          ...       ...        ...        ...        ...        ...   \n",
       "89995   0.266362  6.185887   7.716837  10.144664   1.711649   3.849704   \n",
       "89996   5.147059  4.209660  14.482770   1.375031   6.386263  10.107582   \n",
       "89997  14.902807  2.886534   8.683168   4.522339   1.556421  10.971184   \n",
       "89998  12.743029  2.525611  11.050145   6.589943  12.622192  10.596839   \n",
       "89999  11.069077  6.303448  14.031393   1.877340  13.361607   2.164695   \n",
       "\n",
       "              50         51         52     target  \n",
       "0       9.046424   7.895535  11.010677  20.107472  \n",
       "1       9.270888   3.173994  13.921871  61.763713  \n",
       "2      11.255721  12.794841  12.080951  74.651162  \n",
       "3       0.258284   9.317696   5.383098  69.424645  \n",
       "4       6.816217   8.586960   4.512419  66.767304  \n",
       "...          ...        ...        ...        ...  \n",
       "89995  12.401903  14.195540   2.371207  24.563878  \n",
       "89996  12.637902   6.576331   6.863238  13.861690  \n",
       "89997   7.792226   8.422623   3.041409  38.633704  \n",
       "89998   0.647584   8.746364   1.246682  13.687309  \n",
       "89999  11.255181   3.404303   9.587379  59.613207  \n",
       "\n",
       "[90000 rows x 54 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('internship_train.csv')\n",
    "targets = df['target']\n",
    "#dataset.isna().sum()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d9f4ccec-102a-4cac-a7c5-f4c679f3ba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(columns='target'), \n",
    "    targets, \n",
    "    test_size=0.3, \n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6f2c3944-3275-4890-a6c1-520c3e6f9b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='model.h5', monitor = 'val_loss', verbose = 1, save_best_only = True, mode = 'min'),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n",
    "                                   patience=3, \n",
    "                                   verbose=1, mode='min', min_delta=0.0001, cooldown=2, min_lr=1e-6)   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a679c698-7e36-4193-954e-452b9fe0182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "\n",
    "\n",
    "normalizer = layers.Normalization(input_shape=[53,], axis=None)\n",
    "\n",
    "def build_and_compile_model(norm):\n",
    "    model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(32, activation='relu'),\n",
    "      layers.Dense(16, activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001), metrics = ['RootMeanSquaredError'] )\n",
    "    return model\n",
    "\n",
    "model = build_and_compile_model(normalizer)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "16c61258-7548-4555-9fc3-086a8eb66886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 25.8097 - root_mean_squared_error: 30.3570 - val_loss: 25.5073 - val_root_mean_squared_error: 29.6310\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 25.50733, saving model to model.h5\n",
      "Epoch 2/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 25.3728 - root_mean_squared_error: 29.5202 - val_loss: 25.4360 - val_root_mean_squared_error: 29.5231\n",
      "\n",
      "Epoch 00002: val_loss improved from 25.50733 to 25.43604, saving model to model.h5\n",
      "Epoch 3/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 25.2852 - root_mean_squared_error: 29.3966 - val_loss: 25.3154 - val_root_mean_squared_error: 29.3342\n",
      "\n",
      "Epoch 00003: val_loss improved from 25.43604 to 25.31544, saving model to model.h5\n",
      "Epoch 4/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 25.2784 - root_mean_squared_error: 29.3549 - val_loss: 25.3726 - val_root_mean_squared_error: 29.3990\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 25.31544\n",
      "Epoch 5/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 25.2544 - root_mean_squared_error: 29.3187 - val_loss: 25.4209 - val_root_mean_squared_error: 29.5180\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 25.31544\n",
      "Epoch 6/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 25.2091 - root_mean_squared_error: 29.2765 - val_loss: 25.2961 - val_root_mean_squared_error: 29.2966\n",
      "\n",
      "Epoch 00006: val_loss improved from 25.31544 to 25.29606, saving model to model.h5\n",
      "Epoch 7/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 25.2016 - root_mean_squared_error: 29.2676 - val_loss: 25.2753 - val_root_mean_squared_error: 29.2910\n",
      "\n",
      "Epoch 00007: val_loss improved from 25.29606 to 25.27533, saving model to model.h5\n",
      "Epoch 8/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 18.5911 - root_mean_squared_error: 23.7069 - val_loss: 4.5488 - val_root_mean_squared_error: 5.8214\n",
      "\n",
      "Epoch 00008: val_loss improved from 25.27533 to 4.54884, saving model to model.h5\n",
      "Epoch 9/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 4.3313 - root_mean_squared_error: 5.5827 - val_loss: 4.2432 - val_root_mean_squared_error: 5.4726\n",
      "\n",
      "Epoch 00009: val_loss improved from 4.54884 to 4.24315, saving model to model.h5\n",
      "Epoch 10/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 3.7129 - root_mean_squared_error: 4.8113 - val_loss: 4.2305 - val_root_mean_squared_error: 5.3677\n",
      "\n",
      "Epoch 00010: val_loss improved from 4.24315 to 4.23052, saving model to model.h5\n",
      "Epoch 11/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 3.5258 - root_mean_squared_error: 4.5986 - val_loss: 3.6848 - val_root_mean_squared_error: 4.8195\n",
      "\n",
      "Epoch 00011: val_loss improved from 4.23052 to 3.68477, saving model to model.h5\n",
      "Epoch 12/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 3.4299 - root_mean_squared_error: 4.5135 - val_loss: 3.9189 - val_root_mean_squared_error: 5.0774\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.68477\n",
      "Epoch 13/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 3.2265 - root_mean_squared_error: 4.2534 - val_loss: 3.0601 - val_root_mean_squared_error: 4.0091\n",
      "\n",
      "Epoch 00013: val_loss improved from 3.68477 to 3.06012, saving model to model.h5\n",
      "Epoch 14/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 3.1788 - root_mean_squared_error: 4.2003 - val_loss: 3.1942 - val_root_mean_squared_error: 4.1746\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.06012\n",
      "Epoch 15/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 3.0322 - root_mean_squared_error: 4.0269 - val_loss: 3.4133 - val_root_mean_squared_error: 4.4151\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.06012\n",
      "Epoch 16/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 3.1352 - root_mean_squared_error: 4.1569 - val_loss: 2.8031 - val_root_mean_squared_error: 3.7481\n",
      "\n",
      "Epoch 00016: val_loss improved from 3.06012 to 2.80313, saving model to model.h5\n",
      "Epoch 17/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 3.0391 - root_mean_squared_error: 4.0355 - val_loss: 3.3724 - val_root_mean_squared_error: 4.4677\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.80313\n",
      "Epoch 18/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 3.0214 - root_mean_squared_error: 4.0073 - val_loss: 2.7345 - val_root_mean_squared_error: 3.6407\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.80313 to 2.73446, saving model to model.h5\n",
      "Epoch 19/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 2.9173 - root_mean_squared_error: 3.8826 - val_loss: 2.6567 - val_root_mean_squared_error: 3.5315\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.73446 to 2.65666, saving model to model.h5\n",
      "Epoch 20/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 2.8650 - root_mean_squared_error: 3.8187 - val_loss: 2.7840 - val_root_mean_squared_error: 3.7544\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.65666\n",
      "Epoch 21/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 2.8936 - root_mean_squared_error: 3.8559 - val_loss: 2.4786 - val_root_mean_squared_error: 3.3632\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.65666 to 2.47859, saving model to model.h5\n",
      "Epoch 22/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 2.8618 - root_mean_squared_error: 3.8143 - val_loss: 2.4366 - val_root_mean_squared_error: 3.3009\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.47859 to 2.43657, saving model to model.h5\n",
      "Epoch 23/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 2.8005 - root_mean_squared_error: 3.7486 - val_loss: 3.5182 - val_root_mean_squared_error: 4.3984\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.43657\n",
      "Epoch 24/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 2.6898 - root_mean_squared_error: 3.5990 - val_loss: 3.2618 - val_root_mean_squared_error: 4.2267\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.43657\n",
      "Epoch 25/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 2.7259 - root_mean_squared_error: 3.6457 - val_loss: 2.8235 - val_root_mean_squared_error: 3.7300\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.43657\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 26/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 2.4318 - root_mean_squared_error: 3.2827 - val_loss: 2.6291 - val_root_mean_squared_error: 3.4788\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.43657\n",
      "Epoch 27/40\n",
      "788/788 [==============================] - 2s 2ms/step - loss: 2.4624 - root_mean_squared_error: 3.3230 - val_loss: 2.6165 - val_root_mean_squared_error: 3.4570\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.43657\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=64,validation_split = 0.2, epochs=40, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "68c4979d-3183-458b-bc1e-3fc11e75f00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_root_mean_squared_error</th>\n",
       "      <th>lr</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.800488</td>\n",
       "      <td>3.748645</td>\n",
       "      <td>3.518194</td>\n",
       "      <td>4.398438</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.689798</td>\n",
       "      <td>3.598962</td>\n",
       "      <td>3.261752</td>\n",
       "      <td>4.226729</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.725936</td>\n",
       "      <td>3.645729</td>\n",
       "      <td>2.823494</td>\n",
       "      <td>3.730011</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.431846</td>\n",
       "      <td>3.282713</td>\n",
       "      <td>2.629119</td>\n",
       "      <td>3.478809</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.462377</td>\n",
       "      <td>3.322964</td>\n",
       "      <td>2.616546</td>\n",
       "      <td>3.457029</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  root_mean_squared_error  val_loss  val_root_mean_squared_error  \\\n",
       "22  2.800488                 3.748645  3.518194                     4.398438   \n",
       "23  2.689798                 3.598962  3.261752                     4.226729   \n",
       "24  2.725936                 3.645729  2.823494                     3.730011   \n",
       "25  2.431846                 3.282713  2.629119                     3.478809   \n",
       "26  2.462377                 3.322964  2.616546                     3.457029   \n",
       "\n",
       "        lr  epoch  \n",
       "22  0.0010     22  \n",
       "23  0.0010     23  \n",
       "24  0.0010     24  \n",
       "25  0.0005     25  \n",
       "26  0.0005     26  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "420bea9b-2b3b-466d-8b17-0bfcdb5cf6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.ylim([0, 30])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error [MPG]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "36d4a33e-9bb1-4ca3-9342-4abe982f253b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f59bdd-0b92-452e-ad4b-c6c7b211aa62",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "80a17fd1-6cb0-40ac-8684-ae7899865ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8ecf8f88-33c2-4456-85dd-e6796fd657e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)\n",
    "preds_df = pd.DataFrame(preds, columns = ['preds'])\n",
    "test_targets = pd.DataFrame(y_test, columns = ['target']).reset_index().drop(columns = ['index'])\n",
    "MSE_df = pd.DataFrame(np.square(np.subtract(test_targets['target'], preds_df['preds'])), columns = ['MSE'])\n",
    "ABS_df = pd.DataFrame(np.abs(np.subtract(test_targets['target'], preds_df['preds'])), columns = ['ABS'])\n",
    "res_df = preds_df.join([test_targets, ABS_df, MSE_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "76a5f086-42fa-49e5-8d99-d56fdfc0b879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds</th>\n",
       "      <th>target</th>\n",
       "      <th>ABS</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72.955215</td>\n",
       "      <td>71.802807</td>\n",
       "      <td>1.152408</td>\n",
       "      <td>1.328045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.137520</td>\n",
       "      <td>39.221327</td>\n",
       "      <td>4.083808</td>\n",
       "      <td>16.677485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.865417</td>\n",
       "      <td>7.676630</td>\n",
       "      <td>1.811213</td>\n",
       "      <td>3.280491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85.356689</td>\n",
       "      <td>92.384679</td>\n",
       "      <td>7.027989</td>\n",
       "      <td>49.392635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.907715</td>\n",
       "      <td>93.163612</td>\n",
       "      <td>3.255897</td>\n",
       "      <td>10.600864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26995</th>\n",
       "      <td>60.447693</td>\n",
       "      <td>55.074054</td>\n",
       "      <td>5.373639</td>\n",
       "      <td>28.875994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26996</th>\n",
       "      <td>71.161842</td>\n",
       "      <td>75.312443</td>\n",
       "      <td>4.150601</td>\n",
       "      <td>17.227487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26997</th>\n",
       "      <td>45.431793</td>\n",
       "      <td>48.627577</td>\n",
       "      <td>3.195784</td>\n",
       "      <td>10.213035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26998</th>\n",
       "      <td>97.066284</td>\n",
       "      <td>95.721972</td>\n",
       "      <td>1.344312</td>\n",
       "      <td>1.807174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26999</th>\n",
       "      <td>77.545677</td>\n",
       "      <td>81.227740</td>\n",
       "      <td>3.682063</td>\n",
       "      <td>13.557585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           preds     target       ABS        MSE\n",
       "0      72.955215  71.802807  1.152408   1.328045\n",
       "1      35.137520  39.221327  4.083808  16.677485\n",
       "2       5.865417   7.676630  1.811213   3.280491\n",
       "3      85.356689  92.384679  7.027989  49.392635\n",
       "4      89.907715  93.163612  3.255897  10.600864\n",
       "...          ...        ...       ...        ...\n",
       "26995  60.447693  55.074054  5.373639  28.875994\n",
       "26996  71.161842  75.312443  4.150601  17.227487\n",
       "26997  45.431793  48.627577  3.195784  10.213035\n",
       "26998  97.066284  95.721972  1.344312   1.807174\n",
       "26999  77.545677  81.227740  3.682063  13.557585\n",
       "\n",
       "[27000 rows x 4 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92ccde2-04ba-4bd2-9e58-71e4cfa323cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
